{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Question & Answering with Amazon Bedrock using LangChain\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "이전에는 모델이 타이어 교체 방법을 알려주는 것을 보았지만 관련 데이터를 수동으로 제공하고 컨텍스트를 직접 제공해야 했습니다. 우리는 Bedrock에서 사용할 수 있는 모델을 활용하고 교육 중에 학습한 지식과 수동 컨텍스트 제공을 기반으로 질문하는 접근 방식을 탐색했습니다. 이러한 접근 방식은 짧은 문서나 단일 톤 애플리케이션에서는 작동하지만, 모델에 전송된 프롬프트에 모두 들어맞을 수 없는 대규모 기업 문서가 있을 수 있는 기업 수준의 질문 응답으로 확장되지 않습니다. \n",
    "\n",
    "### Pattern\n",
    "RAG(검색 증강 생성)라는 아키텍처를 구현하여 이 프로세스를 개선할 수 있습니다. RAG는 언어 모델 외부(비모수적)에서 데이터를 검색하고 검색된 관련 데이터를 컨텍스트에 추가하여 프롬프트를 강화합니다.\n",
    "\n",
    "이 노트에서는 질문 응답 패턴에 접근하여 문서를 찾고 활용하여 사용자 질문에 대한 답변을 제공하는 방법을 설명합니다.\n",
    "\n",
    "### Challenges\n",
    "- 토큰 한도를 초과하는 대용량 문서 관리 방법\n",
    "- 질문과 관련된 문서를 찾는 방법\n",
    "\n",
    "### Proposal\n",
    "위의 과제에 대해 본 노트북에서는 다음과 같은 전략을 제안합니다.\n",
    "\n",
    "#### Prepare documents\n",
    "![Embeddings](./images/Embeddings_lang.png)\n",
    "\n",
    "질문에 답하기 전에 문서를 처리하고 문서 chunk 색인에 저장해야 합니다.\n",
    "- 문서를 로드\n",
    "- 더 작은 청크(chunk)로 처리하고 분할합니다.\n",
    "- Amazon Bedrock Titan Embeddings 모델을 사용하여 각 청크의 수치 벡터 표현 생성\n",
    "- 청크와 해당 임베딩을 사용하여 인덱스 생성\n",
    "\n",
    "#### Ask question\n",
    "![Question](./images/Chatbot_lang.png)\n",
    "\n",
    "문서 색인이 준비되면 질문할 준비가 된 것이며, 질문한 질문에 따라 관련 문서를 가져옵니다. 다음 단계가 실행됩니다.\n",
    "- 입력 질문의 임베딩 생성\n",
    "- 질문 임베딩과 인덱스의 임베딩을 비교합니다.\n",
    "- (상위 N) 관련 문서 청크를 가져옵니다.\n",
    "- 프롬프트에서 컨텍스트의 일부로 해당 청크를 추가합니다.\n",
    "- Amazon Bedrock의 모델에 프롬프트를 보냅니다.\n",
    "- 검색된 문서를 기반으로 상황에 맞는 답변을 얻습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usecase\n",
    "#### Dataset\n",
    "이 아키텍처 패턴을 설명하기 위해 IRS의 문서를 사용합니다. 이 문서에서는 다음과 같은 주제를 설명합니다:\n",
    "- OID(원래 발행 할인) 상품\n",
    "- $10,000 이상의 현금 지급을 IRS에 신고\n",
    "- 고용주 세금 안내\n",
    "\n",
    "#### Persona\n",
    "IRS의 작동 방식과 일부 조치가 영향을 미치는지 여부를 이해하지 못하는 일반인의 페르소나를 가정해 보겠습니다.\n",
    "\n",
    "모델은 문서를 바탕으로 쉬운 언어로 답변하려고 노력할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "RAG 접근 방식을 따르기 위해 이 노트북은 RAG와 같은 패턴을 효율적으로 구축할 수 있는 다양한 서비스 및 도구와 통합된 LangChain 프레임워크를 사용하고 있습니다. 우리는 다음 도구를 사용할 것입니다:\n",
    "\n",
    "- **LLM (Large Language Model)**: Anthropic Claude V1 available through Amazon Bedrock\n",
    "\n",
    "  이 모델은 문서 청크(chunk)를 이해하고 인간 친화적인 방식으로 답변을 제공하는 데 사용됩니다.\n",
    "- **Embeddings Model**: Amazon Titan Embeddings available through Amazon Bedrock\n",
    "\n",
    "  이 모델은 텍스트 문서의 수치 표현을 생성하는 데 사용됩니다.\n",
    "- **Document Loader**: PDF Loader available through LangChain\n",
    "\n",
    "  이는 소스에서 문서를 로드할 수 있는 로더입니다. 이 노트북을 위해 로컬 경로에서 샘플 파일을 로드합니다. 이는 기업 내부 시스템에서 문서를 로드하는 로더로 쉽게 대체될 수 있습니다.\n",
    "\n",
    "- **Vector Store**: FAISS available through LangChain\n",
    "\n",
    "  이 노트북에서는 이 메모리 내 벡터 chunk를 사용하여 임베딩과 문서를 모두 저장합니다. 엔터프라이즈 환경에서는 이는 AWS OpenSearch, pgVector가 포함된 RDS Postgres, ChromaDB, Pinecone 또는 Weaviate와 같은 영구 chunk로 대체될 수 있습니다.\n",
    "\n",
    "- **Index**: VectorIndex\n",
    "\n",
    "  인덱스는 입력 임베딩과 문서 임베딩을 비교하여 관련 문서를 찾는 데 도움이 됩니다.\n",
    "- **Wrapper**: 인덱스, 벡터 chunk, 임베딩 모델 및 LLM을 래핑하여 사용자로부터 논리를 추상화합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "이 노트북의 나머지 부분을 실행하기 전에 아래 셀을 실행하여 (필요한 라이브러리가 설치되어 있는지 확인하고) Bedrock에 연결해야 합니다.\n",
    "\n",
    "설정 작동 방식과 ⚠️ **변경이 필요한지 여부**에 대한 자세한 내용은 [Bedrock boto3 setup notebook](../00_Setup/setup.ipynb) 노트북을 참조하세요.\n",
    "\n",
    "이 노트북에는 몇 가지 추가 종속성도 필요합니다:\n",
    "\n",
    "- [FAISS](https://github.com/facebookresearch/faiss), to store vector embeddings\n",
    "- [PyPDF](https://pypi.org/project/pypdf/), for handling PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain                            0.0.312\n",
      "opensearch-py                        2.3.2\n"
     ]
    }
   ],
   "source": [
    "! pip list | grep langchain\n",
    "! pip list | grep opensearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-east-1\n",
      "  Using profile: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n",
      "\u001b[32m\n",
      "== FM lists ==\u001b[0m\n",
      "{'Claude-Instant-V1': 'anthropic.claude-instant-v1',\n",
      " 'Claude-V1': 'anthropic.claude-v1',\n",
      " 'Claude-V2': 'anthropic.claude-v2',\n",
      " 'Command': 'cohere.command-text-v14',\n",
      " 'Jurassic-2-Mid': 'ai21.j2-mid-v1',\n",
      " 'Jurassic-2-Ultra': 'ai21.j2-ultra-v1',\n",
      " 'Titan-Embeddings-G1': 'amazon.titan-embed-text-v1',\n",
      " 'Titan-Text-G1': 'TBD'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock, print_ww\n",
    "from utils.bedrock import bedrock_info\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "# os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\"\n",
    "\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "print(colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint(bedrock_info.get_list_fm_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure langchain\n",
    "\n",
    "LLM 및 임베딩 모델을 인스턴스화하는 것부터 시작합니다. 여기서는 텍스트 생성을 위해 Anthropic Claude를 사용하고 텍스트 삽입을 위해 Amazon Titan을 사용합니다.\n",
    "\n",
    "참고: Bedrock과 함께 사용 가능한 다른 모델을 선택할 수도 있습니다. 모델을 변경하려면 다음과 같이 `model_id`를 교체하면 됩니다.\n",
    "\n",
    "`llm = Bedrock(model_id=\"amazon.titan-tg1-large\")`\n",
    "\n",
    "Available model IDs include:\n",
    "\n",
    "- `amazon.titan-tg1-large`\n",
    "- `ai21.j2-grande-instruct`\n",
    "- `ai21.j2-jumbo-instruct`\n",
    "- `anthropic.claude-instant-v1`\n",
    "- `anthropic.claude-v1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will be using the Titan Embeddings Model to generate our Embeddings.\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "# - create the Anthropic Model\n",
    "llm = Bedrock(model_id=\"anthropic.claude-v2\", client=boto3_bedrock, model_kwargs={'max_tokens_to_sample':1000})\n",
    "bedrock_embeddings = BedrockEmbeddings(client=boto3_bedrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bedrock(client=<botocore.client.BedrockRuntime object at 0x7f968da55120>, model_id='anthropic.claude-v2', model_kwargs={'max_tokens_to_sample': 1000})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BedrockEmbeddings(client=<botocore.client.BedrockRuntime object at 0x7f968da55120>, region_name=None, credentials_profile_name=None, model_id='amazon.titan-embed-text-v1', model_kwargs=None, endpoint_url=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bedrock_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "먼저 문서 저장소를 구축하기 위해 일부 파일을 다운로드해 보겠습니다. 이 예에서는 여기에서 공개 IRS 문서를 사용합니다.[here](https://www.irs.gov/publications)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "files = [\n",
    "    \"https://www.irs.gov/pub/irs-pdf/p1544.pdf\",\n",
    "    \"https://www.irs.gov/pub/irs-pdf/p15.pdf\",\n",
    "    \"https://www.irs.gov/pub/irs-pdf/p1212.pdf\",\n",
    "]\n",
    "for url in files:\n",
    "    file_path = os.path.join(\"data\", url.rpartition(\"/\")[2])\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다운로드한 후 [DirectoryLoader from PyPDF available under LangChain](https://python.langchain.com/en/latest/reference/modules/document_loaders.html)를 사용하여 문서를 로드하고 더 작은 청크(chunk)로 나눌 수 있습니다.\n",
    "\n",
    "참고: 검색된 문서/텍스트는 질문에 대답하기에 충분한 정보를 포함할 만큼 커야 합니다. 하지만 LLM 프롬프트에 들어갈 만큼 충분히 작습니다. 또한 임베딩 모델에는 입력 토큰 길이가 512개 토큰으로 제한되어 있으며 이는 대략 2000자까지 변환됩니다. 이 사용 사례를 위해 우리는 [RecursiveCharacterTextSplitter](https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/recursive_text_splitter.html)를 사용하여 100자가 겹치는 대략 1000자의 청크를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"./data/\")\n",
    "\n",
    "documents = loader.load()\n",
    "# - in our testing Character split works better with this PDF data set\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 100,\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length among 73 documents loaded is 5850 characters.\n",
      "After the split we have 503 documents more than the original 73.\n",
      "Average length among 503 documents (after split) is 910 characters.\n"
     ]
    }
   ],
   "source": [
    "avg_doc_length = lambda documents: sum([len(doc.page_content) for doc in documents])//len(documents)\n",
    "avg_char_count_pre = avg_doc_length(documents)\n",
    "avg_char_count_post = avg_doc_length(docs)\n",
    "print(f'Average length among {len(documents)} documents loaded is {avg_char_count_pre} characters.')\n",
    "print(f'After the split we have {len(docs)} documents more than the original {len(documents)}.')\n",
    "print(f'Average length among {len(docs)} documents (after split) is {avg_char_count_post} characters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 3개의 PDF 문서를 500개 이하의 작은 청크(chunk)로 분할했습니다. \n",
    "\n",
    "이제 해당 청크 중 하나에 대한 샘플 임베딩이 어떻게 보이는지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embedding of a document chunk:  [ 0.11621094  0.06494141 -0.23730469 ...  0.11962891 -0.29882812\n",
      " -0.27929688]\n",
      "Size of the embedding:  (1536,)\n"
     ]
    }
   ],
   "source": [
    "sample_embedding = np.array(bedrock_embeddings.embed_query(docs[0].page_content))\n",
    "print(\"Sample embedding of a document chunk: \", sample_embedding)\n",
    "print(\"Size of the embedding: \", sample_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유사한 패턴에 따라 전체 코퍼스에 대해 임베딩을 생성하고 벡터 chunk에 저장할 수 있습니다. \n",
    "\n",
    "이는 임베딩 모델과 문서를 입력받아 전체 벡터 저장소를 생성하는 LangChain 내부의 [FAISS](https://github.com/facebookresearch/faiss)  구현을 사용하여 쉽게 수행할 수 있습니다. [LangChain](https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/faiss.html)를 사용하면 프롬프트 생성, 쿼리 임베딩 가져오기, 관련 문서 샘플링 및 LLM 호출과 같은 대부분의 무거운 작업을 추상화할 수 있습니다. [VectorStoreIndexWrapper](https://python.langchain.com/docs/modules/data_connection/retrievers)가 이를 도와줍니다.\n",
    "\n",
    "**⚠️⚠️⚠️ NOTE: it might take few minutes to run the following cell ⚠️⚠️⚠️**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "\n",
    "vectorstore_faiss = FAISS.from_documents(\n",
    "    docs,\n",
    "    bedrock_embeddings,\n",
    ")\n",
    "\n",
    "wrapper_store_faiss = VectorStoreIndexWrapper(vectorstore=vectorstore_faiss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering\n",
    "\n",
    "이제 벡터 저장소가 준비되었으므로 질문을 시작할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreIndexWrapper(vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x7f96874874f0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper_store_faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"\\n\\nHuman:Is it possible that I get sentenced to jail due to failure in filings?\\n\\nAssistant:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 단계는 문서와 비교할 수 있도록 쿼리 임베딩을 만드는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25976562, -0.22558594,  0.26953125, ...,  0.390625  ,\n",
       "       -0.0703125 ,  0.30859375])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding = bedrock_embeddings.embed_query(query)\n",
    "np.array(query_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 쿼리 임베딩을 사용하여 관련 문서를 가져올 수 있습니다. 이제 쿼리는 임베딩으로 표시되어 가장 관련성이 높은 정보를 제공하는 데이터 저장소에 대해 쿼리의 유사성 검색을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 documents are fetched which are relevant to the query.\n",
      "----\n",
      "## Document 1: clerks of federal or state courts are discussed\n",
      "later under Bail received by court clerks.\n",
      "However, you do not have to file Form 8300\n",
      "if the transaction is not related to your trade or\n",
      "business. For example, if you own a jewelry\n",
      "store and sell your personal automobile for\n",
      "more than $10,000 in cash, you would not sub-\n",
      "mit a Form 8300 for that transaction.\n",
      "Transaction defined.  A “transaction” occurs\n",
      "when:\n",
      "Goods, services, or property are sold;\n",
      "Property is rented;\n",
      "Cash is exchanged for other cash;\n",
      "A contribution is made to a trust or escrow\n",
      "account;\n",
      "A loan is made or repaid; or\n",
      "Cash is converted to a negotiable instru-\n",
      "ment, such as a check or a bond.\n",
      "Person defined.  A “person” includes an indi-\n",
      "vidual, a company, a corporation, a partnership,\n",
      "an association, a trust, or an estate.\n",
      "Exempt organizations, including employee\n",
      "plans, are also “persons.” However, exempt or-\n",
      "ganizations do not have to file Form 8300 for a\n",
      "more-than-$10,000 charitable cash contribution.......\n",
      "---\n",
      "## Document 2: reasonable cause exists.\n",
      "If you timely filed your employment tax return, the IRS\n",
      "may also waive deposit penalties if you inadvertently\n",
      "failed to deposit and it was the first quarter that you were\n",
      "required to deposit any employment tax, or if you inadver-\n",
      "tently failed to deposit the first time after your deposit fre-\n",
      "quency changed. You must also meet the net worth and\n",
      "size limitations applicable to awards of administrative and\n",
      "litigation costs under section 7430; for individuals, this\n",
      "means that your net worth can't exceed $2 million, and for\n",
      "businesses, your net worth can't exceed $7 million and\n",
      "you also can't have more than 500 employees.\n",
      "The IRS may also waive the deposit penalty the first\n",
      "time you're required to make a deposit if you inadvertently\n",
      "send the payment to the IRS rather than deposit it by EFT.\n",
      "For amounts not properly or timely deposited, the pen-\n",
      "alty rates are as follows.\n",
      "TIP\n",
      "Page 30 Publication 15 (2023).......\n",
      "---\n",
      "## Document 3: substance,\n",
      "2.Racketeering,\n",
      "3.Money laundering, and\n",
      "4.Any state offense substantially similar to\n",
      "(1), (2), or (3) above.\n",
      "For more information about the rules that apply\n",
      "to court clerks, see Section 1.6050I-2 of the In-\n",
      "come Tax Regulations.\n",
      "What Payments Must Be\n",
      "Reported?\n",
      "You must file Form 8300 to report cash paid to\n",
      "you if it is:\n",
      "1.Over $10,000,\n",
      "2.Received as:\n",
      "a.One lump sum of over $10,000,\n",
      "b.Installment payments that cause the\n",
      "total cash received within 1 year of the initial payment to total more than\n",
      "$10,000, or\n",
      "c.Other previously unreportable pay-\n",
      "ments that cause the total cash re-\n",
      "ceived within a 12-month period to to-\n",
      "tal more than $10,000,\n",
      "3.Received in the course of your trade or\n",
      "business,\n",
      "4.Received from the same buyer (or agent),\n",
      "and\n",
      "5.Received in a single transaction or in rela-\n",
      "ted transactions (defined later).\n",
      "What Is Cash?\n",
      "Cash is:\n",
      "1.The coins and currency of the United\n",
      "States (and any other country), and\n",
      "2.A cashier's check, bank draft, traveler's.......\n",
      "---\n",
      "## Document 4: There are civil penalties for failure to:\n",
      "File a correct Form 8300 by the date it is\n",
      "due, and\n",
      "Provide the required statement to those\n",
      "named in the Form 8300.\n",
      "If you intentionally disregard the requirement\n",
      "to file a correct Form 8300 by the date it is due,\n",
      "the penalty is the greater of:\n",
      "1.$25,000, or\n",
      "2.The amount of cash you received and\n",
      "were required to report (up to $100,000).\n",
      "There are criminal penalties for:\n",
      "Willful failure to file Form 8300,\n",
      "Willfully filing a false or fraudulent Form\n",
      "8300,\n",
      "Stopping or trying to stop Form 8300 from\n",
      "being filed, and\n",
      "Setting up, helping to set up, or trying to\n",
      "set up a transaction in a way that would\n",
      "make it seem unnecessary to file Form\n",
      "8300.\n",
      "If you willfully fail to file Form 8300, you can\n",
      "be fined up to $250,000 for individuals\n",
      "RECORDS($500,000 for corporations) or sentenced to up\n",
      "to 5 years in prison, or both. These dollar\n",
      "amounts are based on Section 3571 of Title 18\n",
      "of the U.S. Code........\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "relevant_documents = vectorstore_faiss.similarity_search_by_vector(query_embedding)\n",
    "print(f'{len(relevant_documents)} documents are fetched which are relevant to the query.')\n",
    "print('----')\n",
    "for i, rel_doc in enumerate(relevant_documents):\n",
    "    print_ww(f'## Document {i+1}: {rel_doc.page_content}.......')\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 관련 문서가 있으므로 LLM을 사용하여 이러한 문서를 기반으로 답변을 생성할 차례입니다.\n",
    "\n",
    "유사성 검색 결과를 기반으로 검색된 관련 문서와 함께 초기 프롬프트를 사용합니다. 그런 다음 이를 결합하여 모델에 피드백하여 결과를 얻는 프롬프트를 생성합니다. 이 시점에서 우리 모델은 매뉴얼에 설명된 대로 특정 자동차의 타이어를 교체할 수 있는 방법에 대한 고도의 정보를 제공해야 합니다.\n",
    "\n",
    "LangChain은 이를 쉽게 수행할 수 있는 방법에 대한 추상화를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick way\n",
    "Vector Store를 둘러싸서 LLM 입력을 받는 LangChain에서 제공하는 Wrapper를 사용할 수 있습니다. 이 Wrapper는 뒤에서 다음 단계를 수행합니다:\n",
    "- 질문을 입력\n",
    "- 질문 임베딩 생성\n",
    "- 관련 문서 가져오기\n",
    "- 프롬프트에 문서와 질문을 채워 넣습니다.\n",
    "- 프롬프트로 모델을 호출하고 사람이 읽을 수 있는 방식으로 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the information provided, it is possible to be sentenced to jail for willful failure to\n",
      "file Form 8300 or for willfully filing a false or fraudulent Form 8300. The passage states:\n",
      "\n",
      "\"There are criminal penalties for:\n",
      "- Willful failure to file Form 8300,\n",
      "- Willfully filing a false or fraudulent Form 8300,\n",
      "- Stopping or trying to stop Form 8300 from being filed, and\n",
      "- Setting up, helping to set up, or trying to set up a transaction in a way that would make it seem\n",
      "unnecessary to file Form 8300.\n",
      "\n",
      "If you willfully fail to file Form 8300, you can be fined up to $250,000 for individuals ($500,000\n",
      "for corporations) or sentenced to up to 5 years in prison, or both.\"\n",
      "\n",
      "So yes, it is possible to be sentenced to jail for up to 5 years for willful failure to properly\n",
      "file Form 8300. The criminal penalties apply for intentional disregard of the reporting\n",
      "requirements.\n"
     ]
    }
   ],
   "source": [
    "answer = wrapper_store_faiss.query(question=query, llm=llm)\n",
    "print_ww(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask a different question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_2 = \"\\n\\nHuman:What is the difference between market discount and qualified stated interest\\n\\nAssistant:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "- Market Discount - This refers to the difference between the price at which you purchased a bond\n",
      "and its stated redemption price at maturity. Market discount arises when the bond trades at a\n",
      "discount to its par value due to an increase in interest rates since the bond was issued. The market\n",
      "discount is considered taxable income when the bond matures or is sold.\n",
      "\n",
      "- Qualified Stated Interest - This refers to the stated interest rate on the bond that is considered\n",
      "taxable as ordinary income each year. The stated interest rate on the bond at the time of issue is\n",
      "considered qualified stated interest. This interest income is taxed annually even if the bond was\n",
      "purchased for an amount less than its par value.\n",
      "\n",
      "So in summary:\n",
      "\n",
      "- Market discount is the difference between the purchase price and par value of a bond, which is\n",
      "taxed at maturity or sale.\n",
      "\n",
      "- Qualified stated interest is the annual interest paid on the bond's face value, which is taxed\n",
      "annually as ordinary income.\n",
      "\n",
      "The key difference is that market discount is taxed once at maturity/sale, while qualified stated\n",
      "interest is taxed annually as ordinary income over the life of the bond.\n"
     ]
    }
   ],
   "source": [
    "answer_2 = wrapper_store_faiss.query(question=query_2, llm=llm)\n",
    "print_ww(answer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customisable option\n",
    "위 시나리오에서는 질문에 대한 상황 인식 답변을 빠르고 쉽게 얻을 수 있는 방법을 탐색했습니다. 이제 문서를 가져오는 방법을 사용자 정의할 수 있는 [RetrievalQA](https://python.langchain.com/en/latest/modules/chains/index_examples/Vector_db_qa.html)의 도움으로 더 사용자 정의 가능한 옵션을 살펴보겠습니다. `chain_type` 매개변수를 사용하여 프롬프트에 추가해야 합니다. 또한 검색해야 하는 관련 문서 수를 제어하려면 아래 셀에서 'k' 매개변수를 변경하여 다른 출력을 확인하세요. 많은 시나리오에서 LLM이 답변을 생성하는 데 사용한 소스 문서가 무엇인지 알고 싶을 수 있습니다. LLM 프롬프트의 컨텍스트에 추가된 문서를 반환하는 `return_source_documents`를 사용하여 출력에서 해당 문서를 가져올 수 있습니다. 'RetrievalQA'를 사용하면 모델에 특정한 사용자 정의 [프롬프트 템플릿](https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html)을 제공할 수도 있습니다.\n",
    "\n",
    "참고: 이 예에서는 Amazon Bedrock에서 LLM으로 Anthropic Claude를 사용하고 있습니다. 이 특정 모델은 입력이 `Human:` 아래에 제공되고 모델이 `Assistant:` 다음에 출력을 생성하도록 요청하는 경우 가장 잘 수행됩니다. 아래 셀에는 LLM이 고정 상태를 유지하고 컨텍스트 외부에서 응답하지 않도록 프롬프트를 제어하는 방법의 예가 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the information provided, it is possible to be sentenced to jail for certain failures\n",
      "related to filing Form 8300. Specifically:\n",
      "\n",
      "- There are criminal penalties for willfully failing to file Form 8300, willfully filing a false or\n",
      "fraudulent Form 8300, stopping or trying to stop Form 8300 from being filed, or setting up\n",
      "transactions to avoid filing.\n",
      "\n",
      "- If you willfully fail to file Form 8300, you can be fined up to $250,000 (individuals) or $500,000\n",
      "(corporations), sentenced to up to 5 years in prison, or both.\n",
      "\n",
      "So in summary, yes, it is possible to be sentenced to jail due to willful failures related to filing\n",
      "Form 8300 correctly and completely. The criminal penalties apply for egregious violations, not\n",
      "simple mistakes. But intentionally not filing or falsifying the form could potentially lead to jail\n",
      "time.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Human: Use the following pieces of context to provide a concise answer to the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Assistant:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore_faiss.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 3}\n",
    "    ),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "query = \"Is it possible that I get sentenced to jail due to failure in filings?\"\n",
    "result = qa({\"query\": query})\n",
    "print_ww(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "1. context to be fed into FM(e.g. Claude-v2)\n",
      "-----------------------------------------------\n",
      "There are civil penalties for failure to:\n",
      "File a correct Form 8300 by the date it is\n",
      "due, and\n",
      "Provide the required statement to those\n",
      "named in the Form 8300.\n",
      "If you intentionally disregard the requirement\n",
      "to file a correct Form 8300 by the date it is due,\n",
      "the penalty is the greater of:\n",
      "1.$25,000, or\n",
      "2.The amount of cash you received and\n",
      "were required to report (up to $100,000).\n",
      "There are criminal penalties for:\n",
      "Willful failure to file Form 8300,\n",
      "Willfully filing a false or fraudulent Form\n",
      "8300,\n",
      "Stopping or trying to stop Form 8300 from\n",
      "being filed, and\n",
      "Setting up, helping to set up, or trying to\n",
      "set up a transaction in a way that would\n",
      "make it seem unnecessary to file Form\n",
      "8300.\n",
      "If you willfully fail to file Form 8300, you can\n",
      "be fined up to $250,000 for individuals\n",
      "RECORDS($500,000 for corporations) or sentenced to up\n",
      "to 5 years in prison, or both. These dollar\n",
      "amounts are based on Section 3571 of Title 18\n",
      "of the U.S. Code.\n",
      "-----------------------------------------------\n",
      "2. context to be fed into FM(e.g. Claude-v2)\n",
      "-----------------------------------------------\n",
      "filed when required, there is a failure -to-file (FTF) penalty\n",
      "of 5% of the unpaid tax due with that return. The maximum\n",
      "penalty is generally 25% of the tax due. Also, for each\n",
      "whole or part month the tax is paid late, there is a fail-\n",
      "ure-to- pay (FTP) penalty of 0.5% per month of the amount\n",
      "of tax. For individual filers only, the FTP penalty is re-\n",
      "duced from 0.5% per month to 0.25% per month if an in-\n",
      "stallment agreement is in effect. You must have filed your\n",
      "return on or before the due date of the return to qualify for\n",
      "the reduced penalty. The maximum amount of the FTP\n",
      "penalty is also 25% of the tax due. If both penalties apply\n",
      "in any month, the FTF penalty is reduced by the amount of\n",
      "the FTP penalty. The penalties won't be charged if you\n",
      "have reasonable cause for failing to file or pay. If you re-\n",
      "ceive a penalty notice, you can provide an explanation of\n",
      "why you believe reasonable cause exists.\n",
      "Note.  In addition to any penalties, interest accrues\n",
      "-----------------------------------------------\n",
      "3. context to be fed into FM(e.g. Claude-v2)\n",
      "-----------------------------------------------\n",
      "clerks of federal or state courts are discussed\n",
      "later under Bail received by court clerks.\n",
      "However, you do not have to file Form 8300\n",
      "if the transaction is not related to your trade or\n",
      "business. For example, if you own a jewelry\n",
      "store and sell your personal automobile for\n",
      "more than $10,000 in cash, you would not sub-\n",
      "mit a Form 8300 for that transaction.\n",
      "Transaction defined.  A “transaction” occurs\n",
      "when:\n",
      "Goods, services, or property are sold;\n",
      "Property is rented;\n",
      "Cash is exchanged for other cash;\n",
      "A contribution is made to a trust or escrow\n",
      "account;\n",
      "A loan is made or repaid; or\n",
      "Cash is converted to a negotiable instru-\n",
      "ment, such as a check or a bond.\n",
      "Person defined.  A “person” includes an indi-\n",
      "vidual, a company, a corporation, a partnership,\n",
      "an association, a trust, or an estate.\n",
      "Exempt organizations, including employee\n",
      "plans, are also “persons.” However, exempt or-\n",
      "ganizations do not have to file Form 8300 for a\n",
      "more-than-$10,000 charitable cash contribution\n"
     ]
    }
   ],
   "source": [
    "def show_context_used(context_list):\n",
    "    for idx, context in enumerate(context_list):\n",
    "        print(\"-----------------------------------------------\")                \n",
    "        print(f\"{idx+1}. context to be fed into FM(e.g. Claude-v2)\")\n",
    "        print(\"-----------------------------------------------\")        \n",
    "        print_ww(context.page_content)        \n",
    "show_context_used(result['source_documents'])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "RAG(검색 증강 생성)에 관한 이 모듈을 완료한 것을 축하합니다! 이는 대규모 언어 모델의 성능과 검색 방법의 정확성을 결합하는 중요한 기술입니다. 검색된 관련 사례로 생성을 강화함으로써 우리가 받은 응답은 더욱 일관되고 일관되며 근거가 있게 됩니다. 당신은 이 혁신적인 접근 방식을 배우는 것에 자부심을 느껴야 합니다. 나는 당신이 얻은 지식이 창의적이고 매력적인 언어 생성 시스템을 구축하는 데 매우 유용할 것이라고 확신합니다. 잘하셨어요!\n",
    "\n",
    "위의 RAG 기반 질문 응답 구현에서 우리는 다음 개념과 Amazon Bedrock 및 LangChain 통합을 사용하여 이를 구현하는 방법을 탐색했습니다.\n",
    "\n",
    "- 문서 로드 및 임베딩 생성을 통해 벡터 저장소 생성\n",
    "- 질문에 대한 문서 검색\n",
    "- LLM에 대한 입력으로 사용되는 프롬프트 준비\n",
    "- 인간 친화적인 방식으로 답변 제시\n",
    "\n",
    "### Take-aways\n",
    "- 다양한 벡터 스토어를 실험해 보세요.\n",
    "- Amazon Bedrock에서 사용 가능한 다양한 모델을 활용하여 대체 출력을 확인하세요.\n",
    "- 임베딩 및 문서 청크의 영구 저장과 같은 옵션 탐색\n",
    "- 엔터프라이즈 데이터 저장소와의 통합\n",
    "\n",
    "# Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
